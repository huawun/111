{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V44bTqjnKFxZ"
      },
      "source": [
        "#Contextual Awareness and Memory Retention\n",
        "\n",
        "copyright 2025, Denis Rothman\n",
        "\n",
        "This educational notebook is an introduction to varying levels of contextual awareness and memory retention of an AI controller's management of a generative AI models's API:\n",
        "\n",
        "1.Stateless and memoryless session  \n",
        "2.Short-term memory session   \n",
        "3.Long-term memory of multiple sessions   \n",
        "4.Long-term memory of multiple cross-topic sessions   \n",
        "\n",
        "The goal of the notebook is to illustrate some of the main contextual awareness and memory retention approaches that the AI controller of a  Generative AI System uses during conversational sessions.\n",
        "\n",
        "**Usage recommendations:** Run the whole notebook in one session. In this notebook, memory retention is explicit in different cells. In *Chapter 2, Building the  Generative AI model controller*, the functionality of this notebook will be automated and managed by an AI controller.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2VKAYbVikQb"
      },
      "source": [
        "# Setting up the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFfEHkuA3Tbr"
      },
      "source": [
        "This notebook was developed in Google Colab. Colab includes many pre-installed libraries and sets `/content/` as the default directory, meaning you can access files directly by their filename if you wish (e.g., `filename` instead of needing to specify `/content/filename`). This differs from local environments, where you'll often need to install libraries or specify full file paths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8_G2ePO11rQ"
      },
      "source": [
        "## File downloading script\n",
        "\n",
        "grequests contains a script to download files from the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vzkCTNNChWAJ",
        "outputId": "f0b82a23-cc23-44f4-86f6-6d3717e66c31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   865  100   865    0     0   4632      0 --:--:-- --:--:-- --:--:--  4650\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kNLfjTfAnFR"
      },
      "source": [
        "## Installing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MFwDZDHOxhJe",
        "outputId": "6e910413-0ee7-43e5-b3f0-7191ea027cc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements01.py' successfully.\n",
            "Downloaded 'openai_setup.py' successfully.\n",
            "Downloaded 'openai_api.py' successfully.\n"
          ]
        }
      ],
      "source": [
        "from grequests import download\n",
        "download(\"commons\",\"requirements01.py\")\n",
        "download(\"commons\",\"openai_setup.py\")\n",
        "download(\"commons\",\"openai_api.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a7i8j5vnpatH",
        "outputId": "3cbea24d-c565-4792-8f70-2653839d4cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'openai'...\n",
            "Installing 'openai' version 1.57.1...\n",
            "'openai' version 1.57.1 is installed.\n"
          ]
        }
      ],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O03SZzGGAreV"
      },
      "source": [
        "### Initializing the OpenAI API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pDn09vPbAXPT",
        "outputId": "fdc408e7-6cbf-48af-c7b7-6feb73d8d558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key initialized successfully.\n"
          ]
        }
      ],
      "source": [
        "google_secrets=True #activates Google secrets in Google Colab\n",
        "if google_secrets==True:\n",
        "  import openai_setup\n",
        "  openai_setup.initialize_openai_api()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zer4gyvICLkI"
      },
      "outputs": [],
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the API_KEY\n",
        "  import os\n",
        "  #API_KEY=[YOUR API_KEY]\n",
        "  #os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "  #openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyRi0ZjbCLkI"
      },
      "source": [
        "### Importing the API call function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0lMhv09G0kzr"
      },
      "outputs": [],
      "source": [
        "# Import the API request function\n",
        "import openai_api\n",
        "from openai_api import make_openai_api_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDj0PUWBrZyt"
      },
      "source": [
        "#  1.Stateless and memoryless session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCRjNVo8DRQH"
      },
      "source": [
        "In this stateless and memoryless example, \"stateless\" indicates that each request is processed independently without retaining information from previous interactions, and \"memoryless\" emphasizes the absence of any built-in mechanism to remember past exchanges. This function is efficient for a single, specific query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjJaT4waPQIh"
      },
      "source": [
        "##Semantic query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7S5OplfgGmaZ"
      },
      "outputs": [],
      "source": [
        "# API message\n",
        "uinput = \"Hawai is on a geological volcano system. Explain:\"\n",
        "mrole = \"system\"\n",
        "mcontent = \"You are an expert in geology.\"\n",
        "user_role = \"user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FXCAITeoEHBt",
        "outputId": "bbb9f003-d530-4634-a6cc-8c6b3b3a372d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hawaii is part of a volcanic system known as a hotspot, which is a region of the Earth's mantle where heat rises as a thermal plume from deep within the Earth. This process is responsible for the formation of the Hawaiian Islands. Here's a detailed explanation of how this system works:\n",
            "\n",
            "1. **Hotspot Theory**: Unlike most volcanic activity, which occurs at tectonic plate boundaries, hotspots are located in the middle of tectonic plates. The Hawaiian hotspot is one of the most well-known examples. It is believed to be a relatively stationary area of intense heat in the mantle that causes melting and volcanic activity at the surface.\n",
            "\n",
            "2. **Mantle Plume**: The hotspot is thought to be fed by a mantle plume, which is an upwelling of abnormally hot rock within the Earth's mantle. As the plume rises, it partially melts due to the decrease in pressure, creating magma.\n",
            "\n",
            "3. **Volcanic Island Chain Formation**: As the Pacific Plate moves over the stationary hotspot, the magma breaks through the crust, forming a volcano. Over time, as the plate continues to move, the volcano is carried away from the hotspot, and a new volcano begins to form in its place. This process creates a chain of volcanic islands and seamounts, known as the Hawaiian-Emperor seamount chain.\n",
            "\n",
            "4. **Island Growth and Erosion**: The islands grow as lava flows accumulate, but they also undergo erosion from wind, water, and waves. Over millions of years, islands can become seamounts as they are eroded and sink below sea level.\n",
            "\n",
            "5. **Active Volcanoes**: The Big Island of Hawaii is currently the youngest and most volcanically active part of the chain, with active volcanoes like Kilauea and Mauna Loa. These volcanoes are shield volcanoes, characterized by their broad, gently sloping sides formed by the flow of low-viscosity basaltic lava.\n",
            "\n",
            "6. **Geological Significance**: The Hawaiian hotspot provides valuable insights into the dynamics of the Earth's interior, plate tectonics, and the lifecycle of volcanic islands. It also helps scientists understand the processes that create and modify the Earth's crust.\n",
            "\n",
            "Overall, the Hawaiian volcanic system is a fascinating example of intraplate volcanism, where volcanic activity occurs away from plate boundaries, driven by the underlying mantle dynamics.\n"
          ]
        }
      ],
      "source": [
        "# API function call\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn7-q-SJPaHD"
      },
      "source": [
        "## Episodic query with a semantic undertone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceR4oudbPgMO"
      },
      "outputs": [],
      "source": [
        "# API message\n",
        "uinput = \"I vividly remember my family's move to Hawaii in the 1970s, how they embraced the warmth of its gentle breezes, the joy of finding a steady job, and the serene beauty that surrounded them. Sum this up in one nice sentence from a personal perspective:?\"\n",
        "mrole = \"system\"\n",
        "mcontent = \"You are an expert in geology.\"\n",
        "user_role = \"user\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icAwaNBhb--z"
      },
      "source": [
        "Augmented input from a text message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl1EizvucDhi"
      },
      "outputs": [],
      "source": [
        "text_message='I agree, we had a wonderful time there.'\n",
        "uninput=text_message+uinput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxiFf7AuPi4V"
      },
      "outputs": [],
      "source": [
        "# API function call\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpk6IC5KN17P"
      },
      "source": [
        "## Stateless and memoryless verification\n",
        "\n",
        "Confirming the session is memoryless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TCN0i3hN504"
      },
      "outputs": [],
      "source": [
        "# API message\n",
        "uinput = \"What question did I just ask you?\"\n",
        "mrole = \"system\"\n",
        "mcontent = \"You already have this information\"\n",
        "user_role = \"user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe9wz2fGOScH"
      },
      "outputs": [],
      "source": [
        "# API function call\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwIbj4GGPS3_"
      },
      "source": [
        "# 2.Short-term memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf9lmXGmP6ZM"
      },
      "source": [
        "A request is processed and retains information from previous interaction through a built-in mechanism to remember a past exchange. This function is efficient for a single session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TldIxfeuQSTl"
      },
      "outputs": [],
      "source": [
        "uinput = \"Hawai is on a geological volcano system. Explain:\"\n",
        "mrole = \"system\"\n",
        "mcontent = \"You are an expert in geology.\"\n",
        "user_role = \"user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teXQsk4rQWdt"
      },
      "outputs": [],
      "source": [
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXMv8bqFQszU"
      },
      "source": [
        "Let's now simumlate the conversational AI feature that is automated in the core module of an AI controller in *Chapter 2, Building the AI_Controller*.\n",
        "\n",
        "The session now remembers the state of the dialog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrF2kbNlQfrb"
      },
      "outputs": [],
      "source": [
        "ninput = \"Sum up your previous response in a short sentence in a maximum of 20 words.\"\n",
        "uinput=\"The current dialog session is :\" + uinput + response + ninput\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJeM_0L3ZYtN"
      },
      "outputs": [],
      "source": [
        "print(\"New response:\",response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnlXAIbuVjbn"
      },
      "source": [
        "# 3.Long-term memory of multiple sessions\n",
        "\n",
        "**Note**: To run this cell, make sure that you have run the 2.Short-term memory section first without closing the session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykca49tl3kq1"
      },
      "source": [
        "#### Saving the previous session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NclxG-kiyl_7"
      },
      "outputs": [],
      "source": [
        "session01=response\n",
        "print(session01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEV9zA6U21Af"
      },
      "source": [
        "#### Without long-term memory between sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_oVA8P52sF3"
      },
      "outputs": [],
      "source": [
        "uinput=\"Is in safe to go there on vacation\"\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlbLA2kd25hl"
      },
      "source": [
        "#### With long-term memory between sessions\n",
        "\n",
        "In this scenario,the output of a previous request is added to the input of the previous request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6NOImrg2dww"
      },
      "outputs": [],
      "source": [
        "ninput = \"Let's continue our dialog.\"\n",
        "uinput=ninput + session01 + \"Would it be safe to go there on vacation?\"\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "#print(\"Dialog:\", uinput,\"\\n\") // optional\n",
        "print(\"Response:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCzH3cmaWHrh"
      },
      "source": [
        "# 4.Long-term memory of multiple cross-topic sessions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0nh4pOZ3f1b"
      },
      "source": [
        "#### Saving the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7Kozrox3slj"
      },
      "outputs": [],
      "source": [
        "session02=uinput + response\n",
        "print(session02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTeqICyJ4D25"
      },
      "outputs": [],
      "source": [
        "ninput =\"I would like to organize a geological visit in Arizona.\"\n",
        "uinput=ninput+\"Where should I start?\"\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "print(\"Dialog:\", uinput,\"\\n\") #optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dx2BrqsqmGX2"
      },
      "outputs": [],
      "source": [
        "print(\"Response:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "livVllea4YCH"
      },
      "outputs": [],
      "source": [
        "session02=response\n",
        "ninput=\"Sum up this dialog in a short paragraph:\"\n",
        "uinput=ninput+ session01 + session02\n",
        "response = openai_api.make_openai_api_call(uinput,mrole,mcontent,user_role)\n",
        "#print(\"Dialog:\", uinput,\"\\n\")#optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhyAu_BunK1q"
      },
      "outputs": [],
      "source": [
        "print(\"Response:\", response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}